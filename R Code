###Code by Alissa Gordon###

##packages needed for kaplan meier survival analysis##
library(survival)
library(survminer)

##establishing experimental variables/inputs##
startingn<-170 #initial subgroup size (subgroups: primary and metastatic)
mmedian<-2 #metastatic lifespan median
effectsize<-1 
pmedian<- mmedian+effectsize#primary lifespan median
plambda<-log(2)/pmedian #finds lambda for which median of exp curve would be pmedian
mlambda<-log(2)/mmedian #finds lambda for which median of exp curve would be mmedian
alpha<-0.1 
beta<-0.1
precision<-0.005 #how close we want to be to our goal power (1-beta)
replications<-100 #number of replications used in sample size calculation
Nincrement<-20 #increment size for sample size determination
yearsrecruiting<-3 #years spent recruiting participants
yearsoftrial<-7 #years of trial

n<-startingn #'n' is subgroup size

#establishing dataframe in the trial function
survival<-NA
group<-NA
enrollment<-NA
newvalue<-NA
total<-2*n
count<-(1:total)
#'n' is subgroup size

status1<-NA #1=death 0=censored
status2<-NA
status<-NA 
time<-NA
d<-data.frame(cbind( count, enrollment, group, survival,newvalue, status1, status2, status, time))

##function for a singular trial of kaplan meier curve##
trials<-function()
{
  group<-rep(c(1,2),each=n) # primary=1 and metastatic=2; n rows created for each treatment (2n total rows)
  enrollment<-runif(2*n, min=0, max=yearsrecruiting) #enrollment randomly generated from a uniform distribution from 0 to yearsrecruiting
  survival<-ifelse (group==1, time<-rexp(n, plambda), time<-rexp(n, mlambda)) #randomly generates survival times based off exponential model and lambda calculated for each group
  
  
  ##establishing censor rate of around 10%##
  censoring<- n%/%5 #20% of data potentially censored (will be around 10% after process); evenly rounded in order to use in sample size estimation (decimals interfere with dataframe size)
  censoringp<-survival[1:censoring] #the first 20% of primary data marked for potential censoring
  censoringm<-survival[n+1:censoring] #the first 20% of metastatic data marked for potential censoring
 
  
  ###creates a new column that generates numbers for the marked data from same exponential dataset##
  for (val in censoringp) {
    censornumberp<-rexp(censoring, plambda)
  } 
  for (val in censoringm){
    censornumberm<-rexp(censoring,mlambda)
  }
  
  d<- data.frame(survival,group, enrollment)
  d['newvalue']<-NA
  d['status1']<-NA #1=death 0=censored
  d['status2']<-NA
  d['status']<-NA 
  d['time']<-NA
  

  ##random censoring##
  for (i in 1:length(censoringp)){
    ifelse(censoringp[i]<censornumberp[i], d$newvalue[i]<-survival[i], d$newvalue[i]<-censornumberp[i])
  } #if the potential censor value is less than the original survival time, subject is censored.  This change in time or lack of change is represented by newvalue
  
  for (i in 1:length(censoringm)){
    ifelse(censoringm[i]<censornumberm[i], d$newvalue[n+i]<-survival[n+i], d$newvalue[n+i]<-censornumberm[i])
  }#same process but with metastatic patients
  
  for (i in 1:length(survival)){
    if (is.na(d$newvalue[i])){
      d$newvalue[i]<-survival[i]
    }
  }
  ##marks censored data based off of randomness##
  for (i in 1:length(survival)){
    ifelse(d$newvalue[i]<survival[i], d$status1[i]<-0, d$status1[i]<-1)
  } 
  
  time<-d$newvalue+enrollment
  
  ##censors if time is more than yearsoftrial##
  for (i in 1: length(survival)){
    ifelse(time[i]>yearsoftrial, d$status2[i]<-0, d$status2[i]<-1)
  } #marks as censored in status2 if time>yearsoftrial
  
  for(i in 1:length(survival)){
    ifelse(d$status2[i]==0,d$newvalue[i]<-yearsoftrial-enrollment[i],d$newvalue[i]<-d$newvalue[i])
  } #if censored, newvalue (variable being analyzed in km curve) is yearsoftrial minus enrollment, otherwise newvalue remains initial survival time
  
  
  
  
  
   ##marks as censored in new variable status if censored either due to time or randomness##
  for(i in 1:length(survival)){
    ifelse(d$status1[i]==0|d$status2[i]==0, d$status[i]<-0, d$status[i]<-1)
  }
  

  ##km curve output and p value##
  kmcurve<-survfit(Surv(d$newvalue, d$status)~group, data=d)  #creates curve model of newvalue, censored by status, and sorted by group
  ggsurvplot(kmcurve, pval=FALSE, break.x.by=1, surv.median.line = "v", risk.table = "nrisk_cumevents", cumcensor=TRUE, xscale=1, xlim=c(0,yearsoftrial))
  survdiff(Surv(d$newvalue)~group) #plots the curve and shows risk, event, and censor table by year
  survdifffxn<- survdiff(Surv(d$newvalue)~group)
  p.val <- 1 - pchisq(survdifffxn$chisq, length(survdifffxn$n) - 1) #finds p value using chi square
  return(p.val) #returns p value for later storage
}  

##histogram of p values from number of replications##
p_vals<-replicate(replications, trials()) #stores returned p value for x replications
hist(p_vals, breaks= seq(0,1, length.out=21), labels=TRUE) #histogram of generated p values with 20 bins (to show 0.05 bin on its own)
abline(v=alpha, col="red")

##calculate power##
significant<-p_vals[p_vals<alpha] #significant p values below the alpha value
power<-length(significant)/length(p_vals) #power defined as significant p values over all p values
print(power)


##code to find sample size for desired power##
goalpower<-1-beta
lowergoal<-goalpower-precision
uppergoal<-goalpower+precision

while (power<lowergoal||power>uppergoal){ #while loop so code repeats until power is within (0.895, 0.9045)
  #if power is too low, Nincrement added onto sample size and new power is found
  if (power<lowergoal){
  n<-n+Nincrement
  total<-2*n
  count<-(1:total)
  d<-data.frame(cbind( count, enrollment, group, survival,newvalue, status1, status2, status, time))
  
  p_vals<-replicate(replications, trials())
  significant<-p_vals[p_vals<alpha]
  power<-length(significant)/length(p_vals)
  print(c(n, power))
  }else{
  #if power is too high, Nincrement reduced to 90% original size and subtracted from sample size, new power is found
    Nincrement<-Nincrement%/%(10/9) #%/% fixes issue of rounding 
    n<-n-Nincrement
    total<-2*n
    count<-(1:total)
    d<-data.frame(cbind( count, enrollment, group, survival,newvalue, status1, status2, status, time))
    
    p_vals<-replicate(replications, trials())
    significant<-p_vals[p_vals<alpha]
    power<-length(significant)/length(p_vals)
    print(c(n, power))
  }
} 

#This will only work if you run through the inside of the function as it looks at a singular run through instead of a stored vector of p values.
##side by side histogram of p and m treatments##
phist<-hist(d$newvalue[d$group==1&d$status==1], breaks = seq(min(d$newvalue), max(d$newvalue), length.out = 11)) #establishes ten even bins, uses only non-censored people in histograms
mhist<-hist(d$newvalue[d$group==2&d$status==1], breaks = seq(min(d$newvalue), max(d$newvalue), length.out = 11))
highestCount <- max(phist$counts, mhist$counts) #finds the highest count in both histograms, used below to create side by side histograms with equal scaling
par(mfrow=c(1,2)) #pairs following histograms
hist(d$newvalue[d$group==1&d$status==1], breaks = seq(min(d$newvalue), max(d$newvalue), length.out = 11),  labels=TRUE, ylim=c(0,highestCount), main='primary survival')
hist(d$newvalue[d$group==2&d$status==1], breaks = seq(min(d$newvalue), max(d$newvalue), length.out = 11),  labels=TRUE, ylim=c(0, highestCount), main='metastatic survival')


